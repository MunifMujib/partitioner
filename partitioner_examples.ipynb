{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usages of the partitioner module \n",
    "### JRW, 4/19/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from partitioner.tools import partitioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default \n",
    "This loads partitioner with all english data and runs the full MWEs algorithm described in https://arxiv.org/pdf/1608.02025.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How\n",
      " \n",
      "could\n",
      " \n",
      "something\n",
      " \n",
      "like\n",
      " \n",
      "this\n",
      " \n",
      "simply\n",
      " \n",
      "pop up\n",
      " \n",
      "out of the blue\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "pa = partitioner()\n",
    "print(\"\\n\".join(pa.partition(\"How could something like this simply pop up out of the blue?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this utilizes the parameterization determined in the above article. To change the threshold partition probabilities for both wordforms (type) and part-of-speech (POS), try the following. Note, lower values of q makes it more difficult for words to join together, and values outside of [0,1] will result in random partitions, which are discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 0.76, 'POS': 0.46}\n",
      "How\n",
      " \n",
      "could\n",
      " \n",
      "something\n",
      " \n",
      "like\n",
      " \n",
      "this\n",
      " \n",
      "simply\n",
      " \n",
      "pop up\n",
      " \n",
      "out of\n",
      " \n",
      "the\n",
      " \n",
      "blue\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "print(pa.q)\n",
    "pa.q['type'] = 0.5\n",
    "print(\"\\n\".join(pa.partition(\"How could something like this simply pop up out of the blue?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced memory overhead\n",
    "First, clear the data and then load all but the largest (Wikipedia) MWE dataset. Note: partitioner will not be able to resolve as many named entities without Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How\n",
      " \n",
      "could\n",
      " \n",
      "something\n",
      " \n",
      "like\n",
      " \n",
      "this\n",
      " \n",
      "simply\n",
      " \n",
      "pop up\n",
      " \n",
      "out of\n",
      " \n",
      "the\n",
      " \n",
      "blue\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "pa.q['type'] = 0.76\n",
    "pa.clear()\n",
    "pa.language = \"en\"\n",
    "for source in [\"wordnet\", \"tweebank\", \"trustpilot\", \"ted\", \"streusle\", \"ritter\", \"lowlands\"]:\n",
    "    pa.source = source\n",
    "    pa.load()\n",
    "print(\"\\n\".join(pa.partition(\"How could something like this simply pop up out of the blue?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run partitioner in a different language\n",
    "partitioner comes with starter data from Wikipedia for nine other languages besides English: Dutch (nl), Finnish (fi), German (de), Greek (el), Italian (it), Polish (pl), Portuguese (pt), Russian (ru), and Spanish (es). Note that this is only starter data for these languages, which being from Wikipedia will mostly only cover nouns, as opposed to more conversational language. To learn more about how data are annotated for MWE segmentation, see https://www.cs.cmu.edu/~nschneid/mwecorpus.pdf for more information on comprehensive MWE annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no known contractions for the de language.\n",
      "Die\n",
      " \n",
      "binäre Suche\n",
      " \n",
      "ist\n",
      " \n",
      "ein\n",
      " \n",
      "Algorithmus\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "pa.clear()\n",
    "pa.language = \"de\"\n",
    "pa.source = \"\"\n",
    "pa.load()\n",
    "print(\"\\n\".join(pa.partition(\"Die binäre Suche ist ein Algorithmus.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition a whole text file\n",
    "In addition to segmenting lines of text, partitioner can be applied to whole files to produce aggregated counts. This results in a rank-frequency distribution, which can be assessed for a bag-of-phrases goodness of fit ($R^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.47\n",
      "\n",
      "\" \": 289.0\n",
      "\"\n",
      "\": 52.0\n",
      "\",\": 29.0\n",
      "\">\": 24.0\n",
      "\"'\": 16.0\n",
      "\"the\": 16.0\n",
      "\".\": 15.0\n",
      "\"#\": 12.0\n",
      "\"\"\": 12.0\n",
      "\"partitioner\": 10.0\n",
      "\":\": 8.0\n",
      "\"(\": 7.0\n",
      "\"of\": 7.0\n",
      "\"=\": 7.0\n",
      "\"data\": 7.0\n",
      "\")\": 7.0\n",
      "\"a\": 6.0\n",
      "\"from\": 5.0\n",
      "\"for\": 4.0\n",
      "\"pa\": 4.0\n",
      "\"with\": 4.0\n",
      "\"The\": 4.0\n",
      "\"to\": 3.0\n",
      "\"source\": 3.0\n",
      "\"segmentation\": 3.0\n"
     ]
    }
   ],
   "source": [
    "pa.clear()\n",
    "pa.language = \"en\"\n",
    "pa.source = \"streusle\"\n",
    "pa.load()\n",
    "pa.partitionText(textfile=\"README.md\")\n",
    "pa.testFit()\n",
    "print(\"R-squared: \"+str(round(pa.rsq,2)))\n",
    "print(\"\")\n",
    "phrases = sorted(pa.frequencies, key = lambda x: pa.frequencies[x], reverse = True)\n",
    "for j in range(25):\n",
    "    phrase = phrases[j]\n",
    "    print(\"\\\"\"+phrase+\"\\\": \"+str(pa.frequencies[phrase]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run non-deterministic partitions\n",
    "The partitioner project and module grew out of a more simplistic, probabilistic framework. Instead of using the MWE partitions, we can maintain the training data and just partition at random, acording to the loaded probabilities. Random partitions ensue when the threshold parameters are outside of [0,1]. To really see the effects, clear out all partition data and use the uniform random partition probability.\n",
    "\n",
    "Also, to run random partitions it is best to turn off part-of-speech tagging, the longest first defined (LFD) algorithm (which ensures that all partitioned MWEs are in fact defined), in addition to limiting the gap size to zero. Note that different runs on the same sentence will produce different partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "Randomness\n",
      " \n",
      "is hard to\n",
      " \n",
      "manage.\n",
      "\n",
      "\n",
      "\n",
      "Randomness is hard to manage.\n"
     ]
    }
   ],
   "source": [
    "pa.clear()\n",
    "print(pa.qunif)\n",
    "pa.q['type'] = -1; pa.q['POS'] = -1\n",
    "pa.doLFD = False\n",
    "pa.doPOS = False\n",
    "pa.maxgap = 0\n",
    "print(\"\\n\".join(pa.partition(\"Randomness is hard to manage.\")))\n",
    "print(\"\\n\\n\")\n",
    "print(\"\\n\".join(pa.partition(\"Randomness is hard to manage.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute non-deterministic partition expectations\n",
    "Rather can computing one-off non-deterministic partitions, which are the result of a random process, we can also compute the expectation. For a given phrase, the computed amount is the \n",
    "\n",
    "* \"expected frequency that a phrase is partitioned from a text, given the partition probabilities\"\n",
    "\n",
    "Essentially, these may be treated like counts, generalizing the n-grams framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average, randomness': 0.125, 'is': 0.25, 'On average': 0.25, 'On average, randomness': 0.125, 'average, randomness is dull': 0.03125, ' ': 2.0, 'randomness is dull.': 0.0625, 'On average, randomness is dull.': 0.03125, ',': 0.5, '.': 0.5, 'is dull.': 0.125, 'average, randomness is dull.': 0.03125, 'On': 0.5, 'On average, randomness is': 0.0625, 'randomness is': 0.125, 'randomness is dull': 0.0625, 'dull': 0.25, 'dull.': 0.25, 'randomness': 0.25, 'average': 0.25, 'On average, randomness is dull': 0.03125, 'is dull': 0.125, 'average, randomness is': 0.0625}\n"
     ]
    }
   ],
   "source": [
    "print(pa.expectation(\"On average, randomness is dull.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
